\documentclass[
  11pt,
  fleqn
]{article}
% [fleqn] left-aligns all equations

\input{preamble/preamble}

% For writing/planning purposes: show paragraph level in TOC
\setcounter{secnumdepth}{3}

\addbibresource{references.bib}
\graphicspath{{fig/}}

\title{Constructing composite ordinal outcomes for clinical trials}
\author{Leon Di Stefano + Ordinal
Working Group}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}

  \todo{Suggested framing of this based on 2025-08-07 meeting with
    Kate and Rob is: advice on constructing ordinal outcomes from
    pre-existing components. In particular, ``constructing'' consists
    of the steps before ``validating'' (using external data). The two
    main headings are proposed to be: ``combining existing outcomes''
  and ``how many categories?''}

  Ordinal outcomes are an increasingly popular choice for clinical trials. This
  paper is a guide to techniques for constructing ordinal outcomes out of
  pre-existing components, aimed at clinicians and their statistical
  collaborators. We discuss three broad mechanisms for combining existing
  ordinal outcomes---including binary, continuous, and time to event
  outcomes---into an ordinal composite: overriding (or ``sequential
  composition''), tie-breaking (or ``hierarchical composition''), and what we
  term ``parallel composition''. We illustrate these mechanisms with examples
  from the literature and discuss how constructing fine-grained composite
  outcomes can improve validity and efficiency---but also why coarser outcomes
  might sometimes be preferred in practice. Finally, we connect these general
  methods for combining ordinal outcomes with the ``prioritized outcomes''
  literature (including win-based and desirability of outcome ranking (DOOR)
  methodologies), clearly delineating the task of constructing composite
  ordinal outcomes from the related but distinct tasks of choosing effect
  measures, choosing estimators, and handling censoring.

\end{abstract}
\newpage
\tableofcontents
\newpage

\section{Introduction}

\subsection{Ordinal outcomes, their recent popularity and advantages}

Ordinal outcomes (or endpoints) rank patients trajectories from better to
worse, but do not treat \emph{differences} in individual patient outcomes as
meaningful. Some ordinal outcomes have a long history in specific disease
areas, for example the modified Rankin scale in acute stroke trials
\citep{broderickEvolutionModifiedRankin2017}, and ordinal outcomes have become
increasingly prominent in clinical resarch following the COVID-19 pandemic when
disease-specific ordinal outcome scales were developed by the WHO and NIAID
\citep{beigelRemdesivirTreatmentCovid192020, marshallMinimalCommonOutcome2020}.
Ordinal outcomes have also been used in a number of adaptive platform trials
\citep{angusREMAPCAPRandomizedEmbedded2020, walkerCodesigningNovelOrdinal2025}.

Two desirable features of outcomes in general are \emph{validity} and
\emph{efficiency}. \emph{Valid} outcomes reflect patient benefit and harm;
\emph{efficient} outcomes are able to discriminate among better- and worse-off
patients with relatively small sample sizes. (Strictly speaking efficiency is a
  property not of outcomes themselves but of estimators of effect measures for
  summarizing differences in outcome distribution---more on this in
\ref{sec:prioritized_outcomes}.)

A great strength of ordinal outcomes is the ease with which they can
be combined.

This can help with validity by

\begin{itemize}
  \item \emph{Handle intercurrent events} by incorporating them into a primary
    outcome, avoiding complexities of alternative strategies like
    principal stratum
    estimands (particular for truncating events like death) while
    yielding more
    statistical efficiency than traditional binary composite outcomes.

  \item \emph{Jointly summarizing efficacy and safety} by incorporating
    safety events into a
    primary outcome; this might be particularly useful in pragmatic
    contexts or where side-effects of an intervention are difficult to identify.

  \item \emph{Combining outcome measures of different types} Allow
    for the combination of discrete and continous outcome
    measures (for
      example a numerical quality of life scale with death as the
      overriding worst
    outcome) and allow for the combination of longitudinal and timepoint or
    ``state'' outcomes in a single measure.
\end{itemize}

Moreover it can help with efficiency by

\begin{itemize}
  \item Provide more information than binary outcomes, making study
    designs more sensitive and precise, and
    therefore more efficient and ethical
\end{itemize}

An example of an outcome which is valid but inefficient might be
death as a binary outcome in a context where deaths
are rare.

An example of an outcome which is efficient but which may be invalid
might be continuously-measured concentrations of a biomarker which is a poor
surrogate for disease progression, or a continuous outcome that
excludes mortality.

\subsection{Objectives/contributions}

The goal of this manuscript is to serve as a guide for clinicians and trialists
in developing ordinal outcomes for their studies.

Another goal is to situate the literature around ``generalized pairwise
comparisons of prioritized outcomes''
\citep{buyseGeneralizedPairwiseComparisons2022}--including win ratio
\citep{pocockWinRatioNew2012} and Desirability of Outcome Ranking (DOOR)
methods \citep{evansDesirabilityOutcomeRanking2015,
ongUnlockingDOORHow2023}--within the broader context of ordinal outcomes and
endpoints. These methods as typically presented implicitly bundle
together 3 distinct things:
(1) a choice of ordinal outcome or endpoint (composed through
tie-breaking in the terminology below); (2)
a choice of effect measure (a.k.a.~target parameter, estimand) based
on the ``independent pairs'' construction, and (3) a method for
handling censoring, particularly when the outcomes making up the
composite include time-to-event information.

\subsubsection{Non-objectives}

\paragraph{Outcomes versus effect measures} It is important to distinguish
``outcomes'' and ``effect measures'' -- both sometimes referred to under the
banner of ``endpoints''. Here we focus on outcomes; we discuss endpoints in a
separate paper \todo{cite}.

\paragraph{Constructing versus validating} We want to distinguish
\emph{choosing} or \emph{constructing} an outcome/effect measure from
\emph{validating} the outcome/effect measure using external data. This paper is
about the first task, choosing (or constructing) the outcome and effect
measure. In practice choosing an outcome and effect measure and validating that
outcome and effect measure in pre-trial data will be an iterative process. Our
focus in this paper is on the ``positive'' side of the process--namely coming
up with, and tweaking, proposed outcomes and effect measures--rather than the
``negative'' side, namely testing or checking proposals with data to assess
whether they have desired properties.

\subsection{Reasons to use ordinal outcomes}

\subsection{Capturing a broader spectrum of benefit and harm}

Example: PASSPORT outcome (Figure \ref{fig:passport_outcome}),
designed to capture benefit and harm across sepsis patients with a
range of different disease severities.

\subsubsection{Augmenting a state or time-to-event outcome with
longitudinal information}

The process of combining ordinal outcomes is more flexible than it
might seem, because many different kinds of outcomes can be treated as ordinal
or summarized in ordinal form. Binary
outcomes are ordinal -- they are the simplest kind of
ordinal outcome -- and so too are continuous outcomes, though
``treating them ordinally'' involves ignoring their numeric values.
Longitudinal trajectory-outcomes can be summarized ordinally---for
example ``worst measurement in the first 28 days of
hospitalization''---and combined with ``state'' outcomes.

Distinguish between ``state'' and ``trajectory'' outcomes. State
variables summarize patient outcomes at a particular moment in time.
Trajectory variables, including times-to-event, summarize patient
state over a timecourse. (In practice ``state'' variables are
actually summaries over an interval like ``day 28 post-randomization''.)

Trajectory and state variables can be incorporated into an
ordinal outcome. For
example (from PASSPORT; Figure \ref{fig:passport_outcome})
``worst pSOFA while
hospitalized until day 28'' and ``length of hospitalization'', which are
longitudinal variables (summary of a trajectory), are combined
with the day 28
state variable ``death''. The REMAP-CAP outcome is similar (Figure
\ref{fig:remap_cap_override}).

Most time-to-event analyses are in fact analyses of an ordinal
outcome. The Cox
model for time-to-event data treats time as ordinal: because the baseline
hazard is not modelled, the model itself is invariant to monotone
rescalings of
the time axis, and the (partial) likelihood (ignoring ties)
depends only on the
ranks of the data (i.e., is a marginal likelihood). The Cox model is
essentially an ordinal stopping ratio model with complementary log-log link.
(Plus handling right-censoring.)

An important concern when incorporating longitudinal information is
to avoid including nonclinical effects of treatment/exposure in the
outcome; \citet{ongUnlockingDOORHow2023} discuss/criticize RADAR
methods from this perspective.

Win methods were inaugurated in
\citet{finkelsteinCombiningMortalityLongitudinal1999} with the
express motivation of combining longitudinal and time-to-event information.

\subsection{Incorporating intercurrent events, especially death,
for validity}

The intercurrent event could be (1) incorporated as a level (2) used
for tie-breaking or overriding.

This is a version of the ``composite strategy'' as described in e.g.
\citet{kahanEstimandsFrameworkPrimer2024}, but we expect it to yield
more efficiency than creating a \emph{binary} composite outcome.

For example overriding a numeric outcome by death.
Example: REMAP-CAP: organ-free survival, overridden by death
(Figure \ref{fig:remap_cap_override}).

\begin{figure}
  \includegraphics[width=5in]{remap_outcome_extra_cropped.jpg}
  \caption{\textbf{Overriding a continuous outcome, illustrated by
    REMAP-CAP}. Outcome from the REMAP-CAP adaptive
    platform trial
    \citep{theremap-capinvestigatorsInterleukin6ReceptorAntagonists2021}.
    Illustrates overriding a numeric ordinal outcome (organ
    support-free days) by a binary ordinal outcome (death; this is
    ``sequential composition''), which
    would also be an intercurrent event. This is another example of
  sequential composition.}
  \label{fig:remap_cap_override}
\end{figure}

\subsection{Gaining statistical efficiency}

(See below.)

\section{Three ways to create composite ordinal outcomes}

\subsection{Reviewing the literature for existing/core outcomes}

\subsection{Overriding, tie-breaking, \& parallel composition}

Term in the literature: ``hierarchical composite endpoints''
\citep{gasparyanDesignAnalysisStudies2022}.

Three broad ways to combine ordinal outcomes:
\begin{enumerate}
  \item \textbf{Sequential composition} Tie-breaking by $B$
    \emph{within either highest or lowest level of $A$}. Also could
    call this ``overriding by $A$''. A special case of this is
    \emph{overriding events} when $A$ is binary.

    This is what win methods do \todo{I \emph{THINK}. Need to go
      through an example very carefully to check it's not in fact
      sequential composition. Check
      \citep{follmannAnalysisOrderedComposite2020} and the $x$ axis of
    their survival plots}
  \item \textbf{Hierarchical composition} Complete tie-breaking of $A$ by
    $B$ (``prioritized outcomes''; lexicographic ordering) within
    \emph{every} level of $A$.

    Sequential composition is complete-tie breaking followed by coarsening.

  \item \textbf{Parallel composition} This is where levels of $A$ are
    combined with levels of $B$ ``in parallel''; high levels of $A$
    are combined with high levels of $B$ and low levels of $A$ with
    low levels of $B$.

    This is not so precisely determined as the other two. We need to
    decided \emph{how} to aggregate. Some ways are
    \begin{itemize}
      \item summing up numeric
        scores
      \item counting different kinds of events
      \item taking the worst level across ordinal outcomes considered
        in parallel (as in BANDICOOT; Figure \ref{fig:parallel_bandicoot}).
    \end{itemize}
\end{enumerate}

Suggested notation:
\begin{itemize}
  \item "$\rightarrow$" and "$\leftarrow$" to denote sequential
    composition/overriding,
  \item "$/$" to denote hierarchical composition/tiebreaking
    (note that this is an asymmetric operation), and
  \item "$|$" to denote parallel composition
\end{itemize}

Examples:

\begin{itemize}
  \item \textbf{Sequential composition} Outcome from PASSPORT,
    depicted in Figure
    \ref{fig:passport_outcome}, is given by
    \[ \text{day 28 status} \leftarrow \text{max pSOFA}
      \leftarrow \text{days
      hospitalized}
    \]
  \item
    \textbf{Hierarchical composition} ``Angina Symptom Score'' outcome from
    \citet{rajkumarPlaceboControlledTrialPercutaneous2023},
    depicted in Figure
    \ref{fig:rajkumar_et_al_outcome}, is given by \[
      \text{adverse clinical event} \leftarrow ((\text{units of
    antianginal medication}) / (\text{episodes of angina})) \]

  \item \textbf{Parallel composition} BANDICOOT outcome
    \citep{walkerCodesigningNovelOrdinal2025}, which is
    \[
      (\text{death, graft loss, or relapse}) \leftarrow
      (\text{viraemia} \;|\;
      \text{CD4+ count} \;|\; \text{organ support})
    \]
\end{itemize}

Aside: \citet{wittkowskiCombiningSeveralOrdinal2004} consider combining
ordinal variables into \emph{partial} orders. Beyond the scope of
this paper.

\begin{figure}
  \includegraphics[width=7in]{passport_ordinal_outcome_sequential.pdf}
  % \includegraphics[width=1in]{passport_ordinal_outcome_colorbar.png}
  \caption{\textbf{Overriding (sequential composition) illustrated
    with the PASSPORT outcome} Ordinal outcome used in the planned
    PASSPORT adaptive
    platform trial. This illustrates sequential composition/overriding:
    of days hospitalized by maximum pSOFA while hospitalized, and of
  both of these by day 28 status.}
  \label{fig:passport_outcome}
\end{figure}

\begin{figure}
  \includegraphics[width=6in]{rajkumar_et_al_outcome.png}
  \caption{\textbf{Tie-breaking (hierarchical composition)
      illustrated with the
    the ORBITA-2 outcome.} ``Angina
    Symptom Score'' ordinal outcome develped in
    \citep{rajkumarPlaceboControlledTrialPercutaneous2023}. This illustrates
    (1) hierarchical composition or complete tie-breaking (of units
      of antianginal medication by
    episodes of angina) and also (2) overriding (of angina episodes and
  angina medication by adverse clinical events)}
  \label{fig:rajkumar_et_al_outcome}
\end{figure}

\begin{figure}
  \includegraphics[width=7in]{parallel_composition_bandicoot.pdf}
  % \includegraphics[width=1in]{passport_ordinal_outcome_colorbar.png}
  \caption{\textbf{Parallel composition illustrated with the
    BANDICOOT outcome}.
    Ordinal outcome used in the planned BANDICOOT adaptive platform trial
    \citep{walkerCodesigningNovelOrdinal2025}. Illustrates \textbf{parallel
  composition} of component outcomes.} \label{fig:parallel_bandicoot}
\end{figure}

\subsubsection{Parallel composition by combining numeric scores}

One option: convert each input factor to a numeric value then sum them up.

A specific example of this, described e.g. by
\citet{ongUnlockingDOORHow2023} in
the infectious disease context, is counting events of a particular
type (corresponds to converting the presence/absence of the event to
a 1/0 binary variable).

This doesn't respect the ordinal nature of the variables. That is, it
implicitly uses information about the \emph{differences} between levels.

\section{How many levels?}

\subsection{Increasing efficiency by shrinking the largest category}

Theory of \citep{whiteheadSampleSizeCalculations1993} says that the relative
efficiency (variance) of an unadjusted treatment comparison using an ordinal
versus continuous outcome in the proportional odds model is given
by $1 - \sum
\overline p_c^3$ where $\overline p_c$ is the marginal probability (averaged
over control and experimental groups) of outcome category $c$.
Efficiency is maximized at $1 - 1/C^2$ where $C$ is the total number of
categories when the probabilities are all equal: $\overline p_c = 1/C$.

The results are based on estimating a common odds ratio, but in large
enough samples are equivalent to the Mann-Whitney-Wilcoxon test, and
therefore to testing the various ``win nulls'' (win probability is
  0.5, win difference
is 0, win ratio is 1).

We have simulation results and some maths to show that the value of $\sum_c
\overline p_c^3$ -- and therefore the (relative) efficiency of the
ordinal outcome -- is essentially a function of the largest category
probability $\overline{p}_{\max} = \max \overline{p}_c$. See Figure
\ref{fig:p_max} for an illustration of the maths.

\begin{figure}
  \includegraphics[width=6in]{p_max_controls_efficiency.png}
  \caption{\textbf{Efficiency gains are controlled by the probability
    of the largest category.} Bounds on the relative efficiency of an
    ordinal outcome
    compared to its continuous counterpart as a function of the maximum
    category probability $p_\text{max}$. Results are based on
    estimating a common odds ratio or testing stochastic ordering
    using the Mann-Whitney-Wilcoxon test. The upper bound (best case
    relative efficiency for a given $p_\text{max}$) is always
    achieved in the
    limit of infinitely many categories ($C = \infty$). The lower bound
    is always achieved when the number of categories is as small as
    possible for a given $p_\text{max}$; in particular when
  $p_\text{max} \geq 0.5$ the worst case occurs with 2 categories.}
  \label{fig:p_max}
\end{figure}

Thus simple advice is: for statistical efficiency, try to make
the proportion
of patients in the largest category small. However a converse is: if the
proportion of patients in the largest category is small, not much
is gained by
fine-graining; a coarser outcome might be easier to communicate.

This should also hold \emph{within strata}.

\subsection{Consider efficiency within levels of strong predictors}

\subsection{Coarsening to avoid comparing ambiguous levels (validity)}

In the PASSPORT outcome (Figure \ref{fig:passport_outcome}), for
example, we include both digit
amputation and ECMO
any time within 28 days post-enrollment under the heading of
``adverse clinical events''.

Including these outcomes within the same level of an
ordinal outcome does not mean assuming that the two outcomes have the
\emph{same} utility. Rather it represents \emph{avoiding comparing}
their utilities. (This was something clinicians asked about more than once.)

Also, we "chunk" longer hospital stays more aggressively to avoid
small categories, for the sake of interpretability.

\subsection{Coarsening for ease of communication}

Too many levels can make it hard to directly compare meaningful
proportions/probabilities.

(Outocmes with very many levels -- even up to of the order of 100 --
aren't really a problem for model fitting with modern software.)

Coarsening, including combining levels and replacing complete
tie-breaks with overrides, could help with this.

\section{Hierarchical ordinal outcomes and pairwise comparison methods}

Terms to define/distinguish:
\begin{itemize}
  \item Desirability of Outcome Ranking (outcome)
  \item Hierarchical composite endpoint (outcome)
  \item Prioritized outcomes (outcome)
  \item Win methods (win probability, win odds, win ratio) (effect
    measure; estimation methods)
  \item Generalized pairwise comparisons (effect measure)
\end{itemize}

These approaches implicitly \textbf{bundle together three different things}:
\begin{enumerate}
  \item Constructing an implicit ordinal outcome through
    hierarchical composition (complete tie-breaking/prioritized outcomes)
  \item
    Targeting a nonparametric effect measure defined via the
    ``pairs'' device (win
    probability/win ratio/win odds/etc.)
  \item Estimating that effect measure in a
    nonparametric/flexible manner using pairs, \textbf{with devices for
    accounting for censoring}
\end{enumerate}

This paper is focused on the first of these steps only.

\citet{follmannAnalysisOrderedComposite2020} is an example of the
approach of explicitly constructing a new ordinal outcome based on a
hierarchy (in this case a hierarchy of 3 times-to-event, with event
times for worse events overriding event times for better ones.).

Why is it useful to consider the three steps separately?

Consider some of the critiques of win methods in
\citet[e.g.~][]{ajufoFallaciesUsingWin2023}

\begin{itemize}
  \item Situating methods in their proper context can help
    trialists make informed choices among them
  \item Win methods can make use of
    plots and diagnostics for general ordinal outcomes, for the
    \emph{implicit}
    ordinal variable
    \begin{itemize}
      \item comparative CDF or ``survival''
        (complementary CDF) plots for assessing stochastic
        monotonicity. \citet{follmannAnalysisOrderedComposite2020}
        also does this.
      \item ridit plots
        \citep{brossHowUseRidit1958,jansenRiditAnalysisReview1984}
        relative to a
        reference group, which should allow one to display both full
        eCDF information
        and also win statistics (based on the interpretation of the
          mean ridit as a win
        probability)
    \end{itemize}e.g.
  \item Ordinal regression models can use win
    methods for model checking; it is also possible to present a
    model-based win
    effect measure alongside a common odds ratio for example. See
    \citep{agrestiOrdinalProbabilityEffect2017} for example,
    which covers both
    latent variable and predicted probability versions.
  \item The outcomes
    \emph{implicitly} constructed using DOOR and win methods may
    contain many
    levels, and may contain levels where an effect is not so
    meaningful (e.g.
    time-to-death when the followup time is short). By \emph{explicitly}
    constructing the associated ordinal outcome one might be
    forced to be more
    aware of this
  \item What is a reasonable win analysis of a specific component
    score? From the traditional ordinal endpoint school of thought
    what would make
    most sense is to \emph{only tie-break for the lowest and highest
      levels of that
    score}, and e.g. plot eCDFs of this new variable. Is this
    what the plots do
    that break down wins and losses by component score?
\end{itemize}

Disadvantages of generalized pairwise comparison approaches
\begin{itemize}
  \item Inherited from downsides of complete tiebreaking
  \item Inherited from downsides of nonparametric/pairwise effect measures
  \item Regression methods exist, but are newer and less battle-tested
\end{itemize}

Our approach is closely related to that of
\citet{follmannAnalysisOrderedComposite2020}, who explicitly consider the
ordinal outcome implicitly constructed by win methods from a time-to-event
analysis of ordered events, and show how right-censoring of event times induces
interval censoring of the cosntructed outcome.

\section{Discussion and Conclusions}

For the purposes of this article we have set aside other desiderata for
outcomes like ease of collection, low missingess, objective ascertainability,
etc.

One point of view is that one would ``ideally'' analyze ordinal outcomes by
reporting the associated expected utilities \todo{cite Berry talk; possibly
cite Lumley blog post; example of utility-weighted Rankin scale} and that since
existing ordinal methods supply such utilities implicitly why not just supply
them explicitly. A counterpoint is that the methods do not, in fact, supply
utilities implicitly. Another is that ordinal outcomes let one ``hedge'' about
precise utilities and this is OK: fully-specified utility function may require
more extensive development and validation or may vary widely across patients.

\subsection{Censoring, consistent measurement, etc. are all
additional aspects of constructing the outcome that need to be considered}

\newpage

\printbibliography

\end{document}
